{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f397416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 5)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 6)) (1.21.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 8)) (9.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 10)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 11)) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 12)) (1.12.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 13)) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 14)) (4.64.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 15)) (3.19.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 18)) (2.10.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 23)) (1.4.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 24)) (0.11.2)\n",
      "Requirement already satisfied: ipython in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 38)) (8.2.0)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 39)) (5.8.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 40)) (0.1.1.post2207130030)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.42.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.0.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anaconda\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2021.3)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (2.11.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.1.2)\n",
      "Requirement already satisfied: backcall in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.18.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\anaconda\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 38)) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n",
      "Requirement already satisfied: pure-eval in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.2.2)\n",
      "Requirement already satisfied: executing in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\anaconda\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (2.0.5)\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398a28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4132b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Shashi Ranjan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-8-29 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a1e529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): DetectionModel(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa291e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRGV5mTIAlRcVMY9H9svkn5lQNSRO0wWY6dfg&usqp=CAU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211c5069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 168x300 1 person, 17 cars, 2 buss, 1 truck\n",
      "Speed: 223.8ms pre-process, 519.8ms inference, 4.0ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556c891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5769d861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 28,  28,  26],\n",
       "         [ 28,  28,  26],\n",
       "         [ 29,  29,  27],\n",
       "         ...,\n",
       "         [ 35,  38,  29],\n",
       "         [ 35,  38,  29],\n",
       "         [ 33,  36,  27]],\n",
       " \n",
       "        [[ 28,  28,  26],\n",
       "         [ 28,  28,  26],\n",
       "         [ 29,  29,  27],\n",
       "         ...,\n",
       "         [ 38,  41,  32],\n",
       "         [ 39,  42,  33],\n",
       "         [ 40,  43,  34]],\n",
       " \n",
       "        [[ 28,  28,  26],\n",
       "         [ 29,  29,  27],\n",
       "         [ 29,  29,  27],\n",
       "         ...,\n",
       "         [ 38,  41,  32],\n",
       "         [ 38,  41,  32],\n",
       "         [ 38,  41,  32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,  21,  22],\n",
       "         [ 24,  22,  23],\n",
       "         [ 27,  25,  26],\n",
       "         ...,\n",
       "         [ 61, 219, 134],\n",
       "         [ 61, 219, 134],\n",
       "         [ 61, 219, 134]],\n",
       " \n",
       "        [[ 21,  19,  20],\n",
       "         [ 25,  23,  24],\n",
       "         [ 26,  24,  25],\n",
       "         ...,\n",
       "         [ 61, 219, 134],\n",
       "         [ 61, 219, 134],\n",
       "         [ 61, 219, 134]],\n",
       " \n",
       "        [[ 30,  28,  29],\n",
       "         [ 33,  31,  32],\n",
       "         [ 29,  27,  28],\n",
       "         ...,\n",
       "         [211, 136,  54],\n",
       "         [208, 138,  56],\n",
       "         [230, 125,  43]]], dtype=uint8)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9650e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb6482",
   "metadata": {},
   "source": [
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef0b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fabcc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images') \n",
    "labels = ['awake', 'drowsy']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ee0b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake\n",
      "Collecting images for awake, image number 0\n",
      "Collecting images for awake, image number 1\n",
      "Collecting images for awake, image number 2\n",
      "Collecting images for awake, image number 3\n",
      "Collecting images for awake, image number 4\n",
      "Collecting images for awake, image number 5\n",
      "Collecting images for awake, image number 6\n",
      "Collecting images for awake, image number 7\n",
      "Collecting images for awake, image number 8\n",
      "Collecting images for awake, image number 9\n",
      "Collecting images for awake, image number 10\n",
      "Collecting images for awake, image number 11\n",
      "Collecting images for awake, image number 12\n",
      "Collecting images for awake, image number 13\n",
      "Collecting images for awake, image number 14\n",
      "Collecting images for awake, image number 15\n",
      "Collecting images for awake, image number 16\n",
      "Collecting images for awake, image number 17\n",
      "Collecting images for awake, image number 18\n",
      "Collecting images for awake, image number 19\n",
      "Collecting images for drowsy\n",
      "Collecting images for drowsy, image number 0\n",
      "Collecting images for drowsy, image number 1\n",
      "Collecting images for drowsy, image number 2\n",
      "Collecting images for drowsy, image number 3\n",
      "Collecting images for drowsy, image number 4\n",
      "Collecting images for drowsy, image number 5\n",
      "Collecting images for drowsy, image number 6\n",
      "Collecting images for drowsy, image number 7\n",
      "Collecting images for drowsy, image number 8\n",
      "Collecting images for drowsy, image number 9\n",
      "Collecting images for drowsy, image number 10\n",
      "Collecting images for drowsy, image number 11\n",
      "Collecting images for drowsy, image number 12\n",
      "Collecting images for drowsy, image number 13\n",
      "Collecting images for drowsy, image number 14\n",
      "Collecting images for drowsy, image number 15\n",
      "Collecting images for drowsy, image number 16\n",
      "Collecting images for drowsy, image number 17\n",
      "Collecting images for drowsy, image number 18\n",
      "Collecting images for drowsy, image number 19\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        time.sleep(2)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decae5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\images\\awake.71eacd8d-2774-11ed-93e6-f375faa71228.jpg\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(IMAGES_PATH, labels[0]+'.'+str(uuid.uuid1())+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef369e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake\n",
      "Collecting images for awake, image number 0\n",
      "data\\images\\awake.79d8c873-2774-11ed-9e06-f375faa71228.jpg\n",
      "Collecting images for awake, image number 1\n",
      "data\\images\\awake.79d8c874-2774-11ed-afe3-f375faa71228.jpg\n",
      "Collecting images for awake, image number 2\n",
      "data\\images\\awake.79d8c875-2774-11ed-99a1-f375faa71228.jpg\n",
      "Collecting images for awake, image number 3\n",
      "data\\images\\awake.79d916fb-2774-11ed-bf21-f375faa71228.jpg\n",
      "Collecting images for awake, image number 4\n",
      "data\\images\\awake.79d916fc-2774-11ed-9c9e-f375faa71228.jpg\n",
      "Collecting images for awake, image number 5\n",
      "data\\images\\awake.79d916fd-2774-11ed-99a2-f375faa71228.jpg\n",
      "Collecting images for awake, image number 6\n",
      "data\\images\\awake.79d93843-2774-11ed-9f0a-f375faa71228.jpg\n",
      "Collecting images for awake, image number 7\n",
      "data\\images\\awake.79d93844-2774-11ed-b673-f375faa71228.jpg\n",
      "Collecting images for awake, image number 8\n",
      "data\\images\\awake.79d93f82-2774-11ed-8535-f375faa71228.jpg\n",
      "Collecting images for awake, image number 9\n",
      "data\\images\\awake.79d94341-2774-11ed-911c-f375faa71228.jpg\n",
      "Collecting images for awake, image number 10\n",
      "data\\images\\awake.79d9bef7-2774-11ed-b9fe-f375faa71228.jpg\n",
      "Collecting images for awake, image number 11\n",
      "data\\images\\awake.79d9bef8-2774-11ed-a5b5-f375faa71228.jpg\n",
      "Collecting images for awake, image number 12\n",
      "data\\images\\awake.79d9d61d-2774-11ed-9130-f375faa71228.jpg\n",
      "Collecting images for awake, image number 13\n",
      "data\\images\\awake.79d9dd37-2774-11ed-932f-f375faa71228.jpg\n",
      "Collecting images for awake, image number 14\n",
      "data\\images\\awake.79d9e02b-2774-11ed-a92b-f375faa71228.jpg\n",
      "Collecting images for awake, image number 15\n",
      "data\\images\\awake.79d9e3ac-2774-11ed-a217-f375faa71228.jpg\n",
      "Collecting images for awake, image number 16\n",
      "data\\images\\awake.79d9e56e-2774-11ed-8293-f375faa71228.jpg\n",
      "Collecting images for awake, image number 17\n",
      "data\\images\\awake.79d9e62e-2774-11ed-94b6-f375faa71228.jpg\n",
      "Collecting images for awake, image number 18\n",
      "data\\images\\awake.79d9edb1-2774-11ed-b602-f375faa71228.jpg\n",
      "Collecting images for awake, image number 19\n",
      "data\\images\\awake.79d9edb2-2774-11ed-93e4-f375faa71228.jpg\n",
      "Collecting images for drowsy\n",
      "Collecting images for drowsy, image number 0\n",
      "data\\images\\drowsy.79d9edb3-2774-11ed-a13e-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 1\n",
      "data\\images\\drowsy.79d9edb4-2774-11ed-974e-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 2\n",
      "data\\images\\drowsy.79d9edb5-2774-11ed-bec8-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 3\n",
      "data\\images\\drowsy.79da20c4-2774-11ed-ae4e-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 4\n",
      "data\\images\\drowsy.79da20c5-2774-11ed-ae48-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 5\n",
      "data\\images\\drowsy.79da20c6-2774-11ed-b593-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 6\n",
      "data\\images\\drowsy.79da20c7-2774-11ed-9109-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 7\n",
      "data\\images\\drowsy.79da20c8-2774-11ed-b36b-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 8\n",
      "data\\images\\drowsy.79da6578-2774-11ed-93c9-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 9\n",
      "data\\images\\drowsy.79da6579-2774-11ed-a11b-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 10\n",
      "data\\images\\drowsy.79da657a-2774-11ed-b6d5-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 11\n",
      "data\\images\\drowsy.79da657b-2774-11ed-a4a7-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 12\n",
      "data\\images\\drowsy.79da657c-2774-11ed-8b99-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 13\n",
      "data\\images\\drowsy.79da657d-2774-11ed-b6ac-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 14\n",
      "data\\images\\drowsy.79da657e-2774-11ed-98a1-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 15\n",
      "data\\images\\drowsy.79da657f-2774-11ed-b42c-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 16\n",
      "data\\images\\drowsy.79da8c0f-2774-11ed-b0b6-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 17\n",
      "data\\images\\drowsy.79da8c10-2774-11ed-97fa-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 18\n",
      "data\\images\\drowsy.79da8c11-2774-11ed-a13a-f375faa71228.jpg\n",
      "Collecting images for drowsy, image number 19\n",
      "data\\images\\drowsy.79da8c12-2774-11ed-b786-f375faa71228.jpg\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        print(imgname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "801c68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'labelImg' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/heartexlabs/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b870fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in d:\\anaconda\\lib\\site-packages (5.15.7)\n",
      "Requirement already satisfied: lxml in d:\\anaconda\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.11 in d:\\anaconda\\lib\\site-packages (from pyqt5) (12.11.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.0 in d:\\anaconda\\lib\\site-packages (from pyqt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7c2363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 500 --data dataset.yaml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe534c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Shashi Ranjan/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-8-29 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:47\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mDetectMultiBackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoshape\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# detection model\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoshape:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:331\u001b[0m, in \u001b[0;36mDetectMultiBackend.__init__\u001b[1;34m(self, weights, device, dnn, data, fp16, fuse)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pt:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(model\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;241m32\u001b[39m)  \u001b[38;5;66;03m# model stride\u001b[39;00m\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py:79\u001b[0m, in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weights, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [weights]:\n\u001b[1;32m---> 79\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:55\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# arbitrary model\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\experimental.py:79\u001b[0m, in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weights, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [weights]:\n\u001b[1;32m---> 79\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43multralytics/yolov5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolov5/runs/train/exp15/weights/last.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\hub.py:540\u001b[0m, in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    537\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    538\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, skip_validation\u001b[38;5;241m=\u001b[39mskip_validation)\n\u001b[1;32m--> 540\u001b[0m model \u001b[38;5;241m=\u001b[39m _load_local(repo_or_dir, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\hub.py:569\u001b[0m, in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m hub_module \u001b[38;5;241m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[0;32m    568\u001b[0m entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m--> 569\u001b[0m model \u001b[38;5;241m=\u001b[39m entry(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    571\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremove(hubconf_dir)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:78\u001b[0m, in \u001b[0;36mcustom\u001b[1;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom\u001b[39m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, autoshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# YOLOv5 custom or local model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\hubconf.py:73\u001b[0m, in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     71\u001b[0m help_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/ultralytics/yolov5/issues/36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     72\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Cache may be out of date, try `force_reload=True` or see \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhelp_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for help.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(s) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp15\\\\weights\\\\last.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help."
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp15/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ae6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
